{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA7Tq7GTpEd1JE8jKyzBk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GlenM42/PCA/blob/main/DataMining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1: PCA"
      ],
      "metadata": {
        "id": "mKD-RNip24Um"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n51MC6b2nzU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# This is going to be our function to perform a PCA:\n",
        "def pca(data, n_components=None):\n",
        "  \"\"\"\n",
        "  :param data: numpy array of shape (n_samples, n_features)\n",
        "  :param n_components: number of principal components to return, optional\n",
        "  :return: transformed data, eigenvalues, eigenvectors\n",
        "  \"\"\"\n",
        "\n",
        "  # Step 1: Center the data\n",
        "  mean = np.mean(data, axis=0)\n",
        "  centered_data = data - mean\n",
        "\n",
        "  # Step 2: Compute the covariance matrix\n",
        "  cov_matrix = np.cov(centered_data, rowvar=False)\n",
        "\n",
        "  # Step 3: Solve the char polynomial\n",
        "  eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "\n",
        "  # Step 3.5: Find the char polynomial\n",
        "  char_poly = np.poly(eigenvalues)\n",
        "\n",
        "  # Step 4: Sort eigenvalues and eigenvectors in descending order of eigenvalues\n",
        "  sorted_ind = np.argsort(eigenvalues)[::-1]\n",
        "  sorted_eigenvalues = eigenvalues[sorted_ind]\n",
        "  sorted_eigenvectors = eigenvectors[:, sorted_ind]\n",
        "\n",
        "  # Step 5: Select the top n_comp if specified\n",
        "  if n_components is not None:\n",
        "    sorted_eigenvectors = sorted_eigenvectors[:, :n_components]\n",
        "\n",
        "  # Step 6: Calculate the explained variance\n",
        "  total_var = np.sum(sorted_eigenvalues)\n",
        "  explained_var = (sorted_eigenvalues / total_var) * 100\n",
        "\n",
        "  # Step 7: Transform the data using the selected eigenvectors\n",
        "  transformed_data = np.dot(centered_data, sorted_eigenvectors)\n",
        "\n",
        "  return {\n",
        "      \"mean\": mean,\n",
        "      'centered_data': centered_data,\n",
        "      'char_poly': char_poly,\n",
        "      'cov_matrix': cov_matrix,\n",
        "      'eigenvalues': sorted_eigenvalues,\n",
        "      'eigenvectors': sorted_eigenvectors,\n",
        "      'explained_variance': explained_var,\n",
        "      'transformed_data': transformed_data\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this function defined, let's use it on our array:"
      ],
      "metadata": {
        "id": "DJubR6Ov4nd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = pca(np.array([[1, -1, 4],\n",
        "                        [2, 1, 3],\n",
        "                        [1, 3, -1],\n",
        "                        [4, -1, 3]]))\n",
        "\n",
        "# Output the results\n",
        "for key, value in results.items():\n",
        "  print(f\"{key.capitalize()}: \\n{value}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMy3I-ol4rDm",
        "outputId": "50319deb-c93f-4017-960c-20ce1c6d1d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: \n",
            "[2.   0.5  2.25]\n",
            "\n",
            "Centered_data: \n",
            "[[-1.   -1.5   1.75]\n",
            " [ 0.    0.5   0.75]\n",
            " [-1.    2.5  -3.25]\n",
            " [ 2.   -1.5   0.75]]\n",
            "\n",
            "Char_poly: \n",
            "[  1.         -10.58333333  17.72222222  -4.48148148]\n",
            "\n",
            "Cov_matrix: \n",
            "[[ 2.         -1.33333333  1.        ]\n",
            " [-1.33333333  3.66666667 -3.83333333]\n",
            " [ 1.         -3.83333333  4.91666667]]\n",
            "\n",
            "Eigenvalues: \n",
            "[8.57829637 1.69722877 0.30780819]\n",
            "\n",
            "Eigenvectors: \n",
            "[[-0.24044331  0.93476288  0.26154421]\n",
            " [ 0.63693183 -0.05138764  0.76920554]\n",
            " [-0.73246492 -0.35153616  0.58302442]]\n",
            "\n",
            "Explained_variance: \n",
            "[81.05476885 16.03680728  2.90842387]\n",
            "\n",
            "Transformed_data: \n",
            "[[-1.99676804 -1.4728697  -0.39505979]\n",
            " [-0.23088278 -0.28934594  0.82187108]\n",
            " [ 4.21328387  0.07926054 -0.23335972]\n",
            " [-1.98563305  1.6829551  -0.19345158]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2: Binary Split"
      ],
      "metadata": {
        "id": "X8Du-H5T_cJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Function to calculate Gini index\n",
        "def gini(y):\n",
        "    counts = Counter(y)\n",
        "    impurity = 1 - sum((count / len(y))**2 for count in counts.values())\n",
        "    return impurity\n",
        "\n",
        "# Function to calculate Entropy\n",
        "def entropy(y):\n",
        "    counts = Counter(y)\n",
        "    impurity = -sum((count / len(y)) * np.log2(count / len(y)) for count in counts.values() if count != 0)\n",
        "    return impurity\n",
        "\n",
        "# Function to perform the binary split and return the best split point\n",
        "def best_split(X, y, feature_labels, method=\"gini\", attribute_type=\"continuous\"):\n",
        "    if method == \"gini\":\n",
        "        impurity_func = gini\n",
        "    elif method == \"entropy\":\n",
        "        impurity_func = entropy\n",
        "    else:\n",
        "        raise ValueError(\"Method must be 'gini' or 'entropy'\")\n",
        "\n",
        "    best_split_point = None\n",
        "    best_impurity = float('inf')\n",
        "    best_left = None\n",
        "    best_right = None\n",
        "    best_feature = None\n",
        "\n",
        "    for col in range(X.shape[1]):\n",
        "        values = X[:, col]\n",
        "        sorted_indices = np.argsort(values)\n",
        "        sorted_values, sorted_labels = values[sorted_indices], y[sorted_indices]\n",
        "        for i in range(1, len(sorted_values)):\n",
        "            split_point = (sorted_values[i - 1] + sorted_values[i]) / 2\n",
        "            left_labels = sorted_labels[:i]\n",
        "            right_labels = sorted_labels[i:]\n",
        "            left_impurity = impurity_func(left_labels)\n",
        "            right_impurity = impurity_func(right_labels)\n",
        "            impurity = (len(left_labels) / len(y)) * left_impurity + (len(right_labels) / len(y)) * right_impurity\n",
        "\n",
        "            if impurity < best_impurity:\n",
        "                best_impurity = impurity\n",
        "                best_split_point = split_point\n",
        "                best_left = (X[sorted_indices[:i], :], y[sorted_indices[:i]])\n",
        "                best_right = (X[sorted_indices[i:], :], y[sorted_indices[i:]])\n",
        "                best_feature = feature_labels[col]  # Track the best feature\n",
        "\n",
        "    return best_split_point, best_left, best_right, best_impurity, best_feature\n",
        "\n",
        "# Main function d_tree to perform the binary split and output important metrics\n",
        "def d_tree(X, y, feature_labels, method=\"gini\", attribute_type=\"continuous\"):\n",
        "    best_split_point, best_left, best_right, best_impurity, best_feature = best_split(X, y, feature_labels, method, attribute_type)\n",
        "\n",
        "    print(f\"Best Feature to Split On: {best_feature}\")\n",
        "    print(f\"Best Split Point: {best_split_point}\")\n",
        "    print(f\"Best Left Group Shape: {best_left[0].shape}\")\n",
        "    print(f\"Best Right Group Shape: {best_right[0].shape}\")\n",
        "    print(f\"Best Impurity (Gini/Entropy): {best_impurity}\")\n",
        "\n",
        "    print(\"\\nLeft Group Labels Distribution:\")\n",
        "    print(Counter(best_left[1]))\n",
        "\n",
        "    print(\"\\nRight Group Labels Distribution:\")\n",
        "    print(Counter(best_right[1]))"
      ],
      "metadata": {
        "id": "Bi784uqa8SP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the functions defined, we can do the calculations on our data:"
      ],
      "metadata": {
        "id": "LmvI6negCEEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Example dataset\n",
        "data = [\n",
        "    [1, 'M', 'Family', 'Small', 'C0'],\n",
        "    [2, 'M', 'Sports', 'Medium', 'C0'],\n",
        "    [3, 'M', 'Sports', 'Medium', 'C0'],\n",
        "    [4, 'M', 'Sports', 'Large', 'C0'],\n",
        "    [5, 'M', 'Sports', 'Extra Large', 'C0'],\n",
        "    [6, 'M', 'Sports', 'Extra Large', 'C0'],\n",
        "    [7, 'F', 'Sports', 'Small', 'C0'],\n",
        "    [8, 'F', 'Sports', 'Small', 'C0'],\n",
        "    [9, 'F', 'Sports', 'Medium', 'C0'],\n",
        "    [10, 'M', 'Luxury', 'Large', 'C0'],\n",
        "    [11, 'M', 'Family', 'Large', 'C1'],\n",
        "    [12, 'M', 'Family', 'Extra Large', 'C1'],\n",
        "    [13, 'M', 'Family', 'Medium', 'C1'],\n",
        "    [14, 'M', 'Family', 'Extra Large', 'C1'],\n",
        "    [15, 'F', 'Luxury', 'Small', 'C1'],\n",
        "    [16, 'F', 'Luxury', 'Medium', 'C1'],\n",
        "    [17, 'F', 'Luxury', 'Medium', 'C1'],\n",
        "    [18, 'F', 'Luxury', 'Medium', 'C1'],\n",
        "    [19, 'F', 'Luxury', 'Medium', 'C1'],\n",
        "    [20, 'F', 'Luxury', 'Large', 'C1']\n",
        "]\n",
        "feature_labels = ['Gender', 'Car Type', 'Shirt Size']\n",
        "\n",
        "# Convert the data into a NumPy array and split into features (X) and labels (y)\n",
        "data = np.array(data)\n",
        "X_raw = data[:, 1:4]  # Features\n",
        "y = data[:, -1]       # Labels\n",
        "\n",
        "# One-hot encoding for categorical features (Gender, Car Type, Shirt Size)\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "X_encoded = encoder.fit_transform(X_raw)\n",
        "encoded_feature_labels = encoder.get_feature_names_out(feature_labels)\n",
        "\n",
        "# Perform the decision tree binary split using Gini for the encoded categorical data\n",
        "d_tree(\n",
        "    X=X_encoded,\n",
        "    y=y,\n",
        "    feature_labels=encoded_feature_labels,\n",
        "    method=\"entropy\",\n",
        "    attribute_type=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZSEwYgMCKgC",
        "outputId": "968a4d80-0383-4558-ef79-704e01c21fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Feature to Split On: Car Type_Luxury\n",
            "Best Split Point: 0.0\n",
            "Best Left Group Shape: (9, 9)\n",
            "Best Right Group Shape: (11, 9)\n",
            "Best Impurity (Gini/Entropy): 0.2417233428068324\n",
            "\n",
            "Left Group Labels Distribution:\n",
            "Counter({'C0': 9})\n",
            "\n",
            "Right Group Labels Distribution:\n",
            "Counter({'C1': 10, 'C0': 1})\n"
          ]
        }
      ]
    }
  ]
}